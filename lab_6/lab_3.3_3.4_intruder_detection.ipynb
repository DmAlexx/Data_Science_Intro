{"cells":[{"cell_type":"markdown","metadata":{"id":"yxNOG2qiT7bb"},"source":["### <Center> Лабораторна робота №6. <br> Ідентифікація користувача за допомогою логістичної регресії"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":1572,"status":"ok","timestamp":1600568419975,"user":{"displayName":"Москаленко В'ячеслав Васильович","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64","userId":"09799116143807457878"},"user_tz":-180},"id":"1_rN0IogT7be","outputId":"f3fd4ebb-99b0-4f78-aecd-4239727aa1c2"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm_notebook\n","from scipy.sparse import csr_matrix, hstack\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import roc_auc_score\n","from sklearn.linear_model import LogisticRegression\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"iT_YKiR6T7br"},"source":["### 1. Завантаження і перетворення даних\n","Дані можна самостійно завантажити за посиланням [сторінка](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). Однак можна цього не робити, оскільки дані вже завантажені для проведення лабораторної роботи"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"elapsed":4568,"status":"ok","timestamp":1600568515464,"user":{"displayName":"Москаленко В'ячеслав Васильович","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64","userId":"09799116143807457878"},"user_tz":-180},"id":"sK2cb4cWT7bw","outputId":"5a30c38e-df4f-435f-e5e8-e8178cb956d8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site1</th>\n","      <th>time1</th>\n","      <th>site2</th>\n","      <th>time2</th>\n","      <th>site3</th>\n","      <th>time3</th>\n","      <th>site4</th>\n","      <th>time4</th>\n","      <th>site5</th>\n","      <th>time5</th>\n","      <th>...</th>\n","      <th>time6</th>\n","      <th>site7</th>\n","      <th>time7</th>\n","      <th>site8</th>\n","      <th>time8</th>\n","      <th>site9</th>\n","      <th>time9</th>\n","      <th>site10</th>\n","      <th>time10</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>session_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21669</th>\n","      <td>56</td>\n","      <td>2013-01-12 08:05:57</td>\n","      <td>55.0</td>\n","      <td>2013-01-12 08:05:57</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>...</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>54843</th>\n","      <td>56</td>\n","      <td>2013-01-12 08:37:23</td>\n","      <td>55.0</td>\n","      <td>2013-01-12 08:37:23</td>\n","      <td>56.0</td>\n","      <td>2013-01-12 09:07:07</td>\n","      <td>55.0</td>\n","      <td>2013-01-12 09:07:09</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>...</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","      <td>NaT</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>77292</th>\n","      <td>946</td>\n","      <td>2013-01-12 08:50:13</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:14</td>\n","      <td>951.0</td>\n","      <td>2013-01-12 08:50:15</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:15</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:16</td>\n","      <td>...</td>\n","      <td>2013-01-12 08:50:16</td>\n","      <td>948.0</td>\n","      <td>2013-01-12 08:50:16</td>\n","      <td>784.0</td>\n","      <td>2013-01-12 08:50:16</td>\n","      <td>949.0</td>\n","      <td>2013-01-12 08:50:17</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:17</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>114021</th>\n","      <td>945</td>\n","      <td>2013-01-12 08:50:17</td>\n","      <td>948.0</td>\n","      <td>2013-01-12 08:50:17</td>\n","      <td>949.0</td>\n","      <td>2013-01-12 08:50:18</td>\n","      <td>948.0</td>\n","      <td>2013-01-12 08:50:18</td>\n","      <td>945.0</td>\n","      <td>2013-01-12 08:50:18</td>\n","      <td>...</td>\n","      <td>2013-01-12 08:50:18</td>\n","      <td>947.0</td>\n","      <td>2013-01-12 08:50:19</td>\n","      <td>945.0</td>\n","      <td>2013-01-12 08:50:19</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:19</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:20</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>146670</th>\n","      <td>947</td>\n","      <td>2013-01-12 08:50:20</td>\n","      <td>950.0</td>\n","      <td>2013-01-12 08:50:20</td>\n","      <td>948.0</td>\n","      <td>2013-01-12 08:50:20</td>\n","      <td>947.0</td>\n","      <td>2013-01-12 08:50:21</td>\n","      <td>950.0</td>\n","      <td>2013-01-12 08:50:21</td>\n","      <td>...</td>\n","      <td>2013-01-12 08:50:21</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:21</td>\n","      <td>951.0</td>\n","      <td>2013-01-12 08:50:22</td>\n","      <td>946.0</td>\n","      <td>2013-01-12 08:50:22</td>\n","      <td>947.0</td>\n","      <td>2013-01-12 08:50:22</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["            site1               time1  site2               time2  site3  \\\n","session_id                                                                \n","21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n","54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n","77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n","114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n","146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n","\n","                         time3  site4               time4  site5  \\\n","session_id                                                         \n","21669                      NaT    NaN                 NaT    NaN   \n","54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n","77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n","114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n","146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n","\n","                         time5  ...               time6  site7  \\\n","session_id                      ...                              \n","21669                      NaT  ...                 NaT    NaN   \n","54843                      NaT  ...                 NaT    NaN   \n","77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n","114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n","146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n","\n","                         time7  site8               time8  site9  \\\n","session_id                                                         \n","21669                      NaT    NaN                 NaT    NaN   \n","54843                      NaT    NaN                 NaT    NaN   \n","77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n","114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n","146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n","\n","                         time9 site10              time10 target  \n","session_id                                                        \n","21669                      NaT    NaN                 NaT      0  \n","54843                      NaT    NaN                 NaT      0  \n","77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n","114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n","146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n","\n","[5 rows x 21 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# завантажимо навчальну і тестову вибірки\n","train_df = pd.read_csv('data/train_sessions.csv',\n","                       index_col='session_id')\n","test_df = pd.read_csv('data/test_sessions.csv',\n","                      index_col='session_id')\n","\n","# приведемо колонку time1, ..., time10 до часового формату\n","times = ['time%s' % i for i in range(1, 11)]\n","train_df[times] = train_df[times].apply(pd.to_datetime)\n","test_df[times] = test_df[times].apply(pd.to_datetime)\n","\n","# відсортуємо дані за часом\n","train_df = train_df.sort_values(by='time1')\n","\n","# подивимося на заголовок навчальної вибірки\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"7ycURxB3T7b5"},"source":["В навчальній вибірці містяться наступні ознаки:\n","    - site1 – індекс першого відвідування сайту в сесії\n","    - time1 – час відвідування першого сайту в сесії\n","    - ...\n","    - site10 – індекс 10-го відвідування сайту в сесії\n","    - time10 – час відвідування 10-го сайту в сесії\n","    - target – цільова змінна, 1 для сесій Еліс, 0 для сесій інших користувачів\n","    \n","Сесії користувачів виділені таким чимном, щоб вони не можут бути довші півгодини чи 10 сайтів. Тобто сесія вважається закінченою або коли користувач відвідав 10 сайтів підряд або коли сесія зайняла за часом більше 30 хвилин.\n","\n","В таблиці зустрічаються пропущені значення, це значить, що сесія містить менше, ніж 10 сайтів. Замінимо пропущені значення нулями і приведемо ознаки до цільового типу. Також заванатажимо словник сайтів і подивимося, як він виглядає:"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"elapsed":572,"status":"ok","timestamp":1600568520266,"user":{"displayName":"Москаленко В'ячеслав Васильович","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64","userId":"09799116143807457878"},"user_tz":-180},"id":"Q82qF45IT7b7","outputId":"89b3aeb2-3590-434b-d82b-2bf4f5b91150"},"outputs":[{"name":"stdout","output_type":"stream","text":["всього сайтів: 48371\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25075</th>\n","      <td>www.abmecatronique.com</td>\n","    </tr>\n","    <tr>\n","      <th>13997</th>\n","      <td>groups.live.com</td>\n","    </tr>\n","    <tr>\n","      <th>42436</th>\n","      <td>majeureliguefootball.wordpress.com</td>\n","    </tr>\n","    <tr>\n","      <th>30911</th>\n","      <td>cdt46.media.tourinsoft.eu</td>\n","    </tr>\n","    <tr>\n","      <th>8104</th>\n","      <td>www.hdwallpapers.eu</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     site\n","25075              www.abmecatronique.com\n","13997                     groups.live.com\n","42436  majeureliguefootball.wordpress.com\n","30911           cdt46.media.tourinsoft.eu\n","8104                  www.hdwallpapers.eu"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# приведемо колонки site1, ..., site10 до цілочислового формату і замінимо пропуски нулями\n","sites = ['site%s' % i for i in range(1, 11)]\n","train_df[sites] = train_df[sites].fillna(0).astype('int')\n","test_df[sites] = test_df[sites].fillna(0).astype('int')\n","\n","# завантажимо словник сайтів\n","with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n","    site_dict = pickle.load(input_file)\n","\n","# датафрейм словника сайтів\n","sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n","                          index=list(site_dict.values()), \n","                          columns=['site'])\n","print(u'всього сайтів:', sites_dict_df.shape[0])\n","sites_dict_df.head()"]},{"cell_type":"markdown","metadata":{"id":"tZobaYZuT7cC"},"source":["Виділимо цільову змінну і об'єднаємо вибірки, щоб разом привести їх до розрідженого формату."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"1b6NQLhlT7cE"},"outputs":[],"source":["# наша цільова змінна\n","y_train = train_df['target']\n","\n","# об'єднана таблиця вхідних даних\n","full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n","\n","# індекс, за яким будемо відокремлювати навчальну вибірку від тестової\n","idx_split = train_df.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"DcuO-EB0T7cN"},"source":["Для самої першої моделі ми використовуємо лише відвідувані сайти в сесіях (але не будемо звертати увагу на часові ознаки). В основі такого вибору даних для моделей лежить така ідея: * у Еліс є свої улюблені сайти, і якщо ви ще побачите ці сайти в сесіях, тим вище ймовірність, що це сесія Еліс і навпаки. *\n","\n","Підготуємо дані, з усієї таблиці виберемо лише ознаки `site1, site2, ..., site10`. Нагадуємо, що пропущені значення замінені нулем. Ось як виглядатимуть перші рядки таблиць:"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1600568525949,"user":{"displayName":"Москаленко В'ячеслав Васильович","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64","userId":"09799116143807457878"},"user_tz":-180},"id":"Ah1VGxPDT7cP","outputId":"01cb599a-27ec-462f-a677-d58532b07121"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site1</th>\n","      <th>site2</th>\n","      <th>site3</th>\n","      <th>site4</th>\n","      <th>site5</th>\n","      <th>site6</th>\n","      <th>site7</th>\n","      <th>site8</th>\n","      <th>site9</th>\n","      <th>site10</th>\n","    </tr>\n","    <tr>\n","      <th>session_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21669</th>\n","      <td>56</td>\n","      <td>55</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>54843</th>\n","      <td>56</td>\n","      <td>55</td>\n","      <td>56</td>\n","      <td>55</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>77292</th>\n","      <td>946</td>\n","      <td>946</td>\n","      <td>951</td>\n","      <td>946</td>\n","      <td>946</td>\n","      <td>945</td>\n","      <td>948</td>\n","      <td>784</td>\n","      <td>949</td>\n","      <td>946</td>\n","    </tr>\n","    <tr>\n","      <th>114021</th>\n","      <td>945</td>\n","      <td>948</td>\n","      <td>949</td>\n","      <td>948</td>\n","      <td>945</td>\n","      <td>946</td>\n","      <td>947</td>\n","      <td>945</td>\n","      <td>946</td>\n","      <td>946</td>\n","    </tr>\n","    <tr>\n","      <th>146670</th>\n","      <td>947</td>\n","      <td>950</td>\n","      <td>948</td>\n","      <td>947</td>\n","      <td>950</td>\n","      <td>952</td>\n","      <td>946</td>\n","      <td>951</td>\n","      <td>946</td>\n","      <td>947</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n","session_id                                                                  \n","21669          56     55      0      0      0      0      0      0      0   \n","54843          56     55     56     55      0      0      0      0      0   \n","77292         946    946    951    946    946    945    948    784    949   \n","114021        945    948    949    948    945    946    947    945    946   \n","146670        947    950    948    947    950    952    946    951    946   \n","\n","            site10  \n","session_id          \n","21669            0  \n","54843            0  \n","77292          946  \n","114021         946  \n","146670         947  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# таблиця з індексами відвіданих сайтів в сесії\n","full_sites = full_df[sites]\n","full_sites.head()"]},{"cell_type":"markdown","metadata":{"id":"yIocdQ-BT7cb"},"source":["Сесії представляють собою послідовність індексів сайтів і дані в такому вигляді невдалі для лінійних методів. Відповідно до нашої гіпотези (у Еліс є улюблені сайти) необхідно перетворити цю таблицю таким чином, щоб кожен можливий веб-сайт відповідав своєму окремому призначенню (колонка), а його значення зростало за кількістю відвідувачів цього веб-сайту в сесіях. Це робиться в два рядки:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VI3OsUzST7cc"},"outputs":[],"source":["from scipy.sparse import csr_matrix"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3Ll_cv4XT7ci"},"outputs":[{"data":{"text/plain":["scipy.sparse._csr.csr_matrix"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["csr_matrix"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"soTapyJpT7co"},"outputs":[],"source":["# послідовність з індексами\n","sites_flatten = full_sites.values.flatten()\n","\n","# шкана матриця\n","full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n","                                sites_flatten,\n","                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]"]},{"cell_type":"markdown","metadata":{"id":"BUMiXftWT7cu"},"source":["Ще один плюс використання розріджених матриць у тому, що для них є спеціальні реалізації як матричних операцій, так і алгоритми машинного навчання, що дозволяє істотно прискорити операції за рахунок особливостей структур даних. Це стосується і логістичної регресії. Ось тепер у нас все готове для побудови наших перших моделей.\n","\n","### 2. Побудова першої моделі\n","\n","Отже, у нас є алгоритм та дані для нього, побудуйте нашу першу модель, використовуючи реалізацію [логістичної регресії] (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) з пакета ` sklearn` з параметрами за замовчуванням. Перші 90% даних будемо використовувати для навчання (навчальна вибірка, відсортована за часом), а також 10% для перевірки якості (validation).\n","\n","**Напишіть просту функцію, яка поверне якість моделей на вкладеній вибірці, і навчіть наш перший класифікатор**."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DS4Y6Zg4T7cv"},"outputs":[],"source":["def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n","    '''\n","    X, y – вибірка\n","    ratio – у якому співвідношенні поділити вибірку\n","    C, seed – коефіцієт регуляризації і random_state \n","              логістичної регресії\n","    '''\n","    \n","   # Розділимо вибірку на навчальну і валідаційну в заданому співвідношенні\n","    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=(1 - ratio), random_state=seed, shuffle=False)\n","    \n","    # Ініціалізуємо логістичну регресію з коефіцієнтом регуляризації C\n","    logreg = LogisticRegression(C=C, random_state=seed, solver='liblinear')\n","    \n","    # Навчаємо модель на навчальних даних\n","    logreg.fit(X_train, y_train)\n","    \n","    # Прогнозуємо ймовірності на валідаційній вибірці\n","    y_pred = logreg.predict_proba(X_valid)[:, 1]\n","    \n","    # Обчислюємо і повертаємо AUC-ROC на валідаційній вибірці\n","    return roc_auc_score(y_valid, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"drho7H3mT7c1"},"source":["**Подивіться, який отримано ROC AUC на відкладеній вибірці.**"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"aZgYq5eGT7c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC-ROC на валідаційній вибірці: 0.9195\n"]}],"source":["# X - це розріджена матриця з індексами сайтів\n","X = full_sites_sparse[:idx_split, :]  # Навчальна вибірка (всі сесії до розділення на навчальні та тестові дані)\n","\n","# y - це цільова змінна, яка вказує, чи належить сесія до Еліс (1) або ні (0)\n","y = y_train.values\n","\n","# Навчання моделі і розрахунок AUC-ROC на валідаційній виборці\n","auc_score = get_auc_lr_valid(X, y, C=1.0, ratio=0.9)\n","\n","# Виведення результату AUC-ROC на валідаційній вибірці\n","print(f'AUC-ROC на валідаційній вибірці: {auc_score:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"vOcbcJt7T7c7"},"source":["Будем вважати цю модель нашою першою відправною точкою (базовий рівень). Для побудови моделей для прогнозування на тестовій вибірці ** необхідно навчити модель заново вже на всій навчальній вибірці ** (покищо наша модель навчилася лише на частині даних), що підвищує її узагальнюючу здатність:"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"caSGwpJNT7c8"},"outputs":[],"source":["# функція для запису прогнозів в файлі\n","def write_to_submission_file(predicted_labels, out_file,\n","                             target='target', index_label=\"session_id\"):\n","    predicted_df = pd.DataFrame(predicted_labels,\n","                                index = np.arange(1, predicted_labels.shape[0] + 1),\n","                                columns=[target])\n","    predicted_df.to_csv(out_file, index_label=index_label)"]},{"cell_type":"markdown","metadata":{"id":"nnrpDV3UT7dE"},"source":["**Навчіть модель на всій вибірці, зробіть прогноз для тестової вибірки і покажіть результат**."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"rO3SFJ87T7dF"},"outputs":[{"name":"stdout","output_type":"stream","text":["['0.0022', '0.0000', '0.0000', '0.0000', '0.0000', '0.0002', '0.0005', '0.0001', '0.0008', '0.1031', '0.0000', '0.0001', '0.0004', '0.3577', '0.0001', '0.0040', '0.0152', '0.0000', '0.0009', '0.0000', '0.0623', '0.0000', '0.0000', '0.0003', '0.0718', '0.0000', '0.0006', '0.0000', '0.0146', '0.0001']\n"]}],"source":["# Підготовка даних\n","X_train_full = full_sites_sparse[:idx_split, :]  # Навчальна вибірка (всі дані)\n","y_train_full = y_train.values  # Цільова змінна\n","\n","# Тестова вибірка\n","X_test = full_sites_sparse[idx_split:, :]  # Тестова вибірка\n","\n","# Ініціалізація логістичної регресії\n","logreg_full = LogisticRegression(C=1.0, random_state=17, solver='liblinear')\n","\n","# Навчання на всій навчальній вибірці\n","logreg_full.fit(X_train_full, y_train_full)\n","\n","# Прогноз для тестової вибірки\n","y_test_pred = logreg_full.predict_proba(X_test)[:, 1]\n","\n","# Виведення перших 30 прогнозів для тестової вибірки\n","print([f'{pred:.4f}' for pred in y_test_pred[:30]])\n","\n","# Запис прогнозів у файл\n","write_to_submission_file(y_test_pred, 'submission.csv')"]},{"cell_type":"markdown","metadata":{"id":"l4rdKvt6T7dL"},"source":["### 3. Покращення моделі, побудова нових ознак"]},{"cell_type":"markdown","metadata":{"id":"sWaNbxfnT7dM"},"source":["Створіть таку ознаку, яка буде представлят собою число формату ГГГГММ від тої дати, коли відбувалась сесія, наприклад 201407 -- 2014 рік і 7 месяц. Таким чином, ми будемо враховувати помісячний [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь період наданих даних."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"2zT4tSJ0T7dN"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time1</th>\n","      <th>year_month</th>\n","    </tr>\n","    <tr>\n","      <th>session_id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21669</th>\n","      <td>2013-01-12 08:05:57</td>\n","      <td>201301</td>\n","    </tr>\n","    <tr>\n","      <th>54843</th>\n","      <td>2013-01-12 08:37:23</td>\n","      <td>201301</td>\n","    </tr>\n","    <tr>\n","      <th>77292</th>\n","      <td>2013-01-12 08:50:13</td>\n","      <td>201301</td>\n","    </tr>\n","    <tr>\n","      <th>114021</th>\n","      <td>2013-01-12 08:50:17</td>\n","      <td>201301</td>\n","    </tr>\n","    <tr>\n","      <th>146670</th>\n","      <td>2013-01-12 08:50:20</td>\n","      <td>201301</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         time1  year_month\n","session_id                                \n","21669      2013-01-12 08:05:57      201301\n","54843      2013-01-12 08:37:23      201301\n","77292      2013-01-12 08:50:13      201301\n","114021     2013-01-12 08:50:17      201301\n","146670     2013-01-12 08:50:20      201301"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Створимо нову ознаку 'year_month' на основі колонки 'time1'\n","# Спочатку переконаємось, що 'time1' приведена до типу datetime\n","train_df['time1'] = pd.to_datetime(train_df['time1'])\n","\n","# Створюємо нову ознаку у форматі ГГГГММ\n","train_df['year_month'] = train_df['time1'].apply(lambda x: 100 * x.year + x.month)\n","\n","# Те саме робимо для тестової вибірки\n","test_df['time1'] = pd.to_datetime(test_df['time1'])\n","test_df['year_month'] = test_df['time1'].apply(lambda x: 100 * x.year + x.month)\n","\n","# Перевіримо, як виглядають перші кілька рядків з новою ознакою\n","train_df[['time1', 'year_month']].head()\n"]},{"cell_type":"markdown","metadata":{"id":"KXjVHoXTT7dT"},"source":["Додайте нову ознаку, попередньо нормалізуючи її за допомогою `StandardScaler`, і знову підрахуйте ROC AUC на відкладеній вибірці."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"jQ1Fl8aNT7dU"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC-ROC на валідаційній вибірці з новою ознакою: 0.9197\n"]}],"source":["# Нормалізуємо цю ознаку за допомогою StandardScaler\n","scaler = StandardScaler()\n","\n","# Застосовуємо scaler до ознаки 'year_month'\n","train_year_month_scaled = scaler.fit_transform(train_df[['year_month']])\n","test_year_month_scaled = scaler.transform(test_df[['year_month']])\n","\n","# Додаємо нормалізовану ознаку до розріджених матриць X (навчальна) і X_test (тестова)\n","X_train_full_with_year_month = hstack([full_sites_sparse[:idx_split, :], train_year_month_scaled])\n","X_test_with_year_month = hstack([full_sites_sparse[idx_split:, :], test_year_month_scaled])\n","\n","# Повторне навчання моделі на нових даних з новою ознакою\n","logreg_full_with_year_month = LogisticRegression(C=1.0, random_state=17, solver='liblinear')\n","logreg_full_with_year_month.fit(X_train_full_with_year_month, y_train.values)\n","\n","# Прогнозування на валідаційній вибірці (знову ділимо навчальну вибірку для перевірки)\n","X_train, X_valid, y_train_split, y_valid = train_test_split(\n","    X_train_full_with_year_month, y_train.values, test_size=0.1, random_state=17, shuffle=False)\n","\n","# Навчання на нових даних з валідацією\n","logreg = LogisticRegression(C=1.0, random_state=17, solver='liblinear')\n","logreg.fit(X_train, y_train_split)\n","\n","# Прогнозування для валідаційної вибірки\n","y_valid_pred = logreg.predict_proba(X_valid)[:, 1]\n","\n","# Обчислюємо AUC-ROC на валідаційній вибірці\n","auc_score = roc_auc_score(y_valid, y_valid_pred)\n","print(f'AUC-ROC на валідаційній вибірці з новою ознакою: {auc_score:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"Tx1-wXJ8T7dY"},"source":["**Додайте дві нові ознаки: start_hour і morning.**\n","\n","Ознака `start_hour` - це час у якому почалася сесія (від 0 до 23), а бінарна оознака` morning` рівна 1, якщо сесія почалася вранці і 0, якщо сесія почалася пізніше (будемо вважати, що це ранок, якщо `start_hour рівний` 11 або менше).\n","\n","**Підрахуйте RUC AUC на відкладеній вибірці для вибірки з:**\n","- сайтами, `start_month` і` start_hour`\n","- сайтами, `start_month` і` morning`\n","- сайтами, `start_month`,` start_hour` і `morning`"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"RIwOQZ8_T7da"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC-ROC на валідаційній вибірці для сайтів, start_month і start_hour: 0.9579\n","AUC-ROC на валідаційній вибірці для сайтів, start_month і morning: 0.9487\n","AUC-ROC на валідаційній вибірці для сайтів, start_month, start_hour і morning: 0.9591\n"]}],"source":["# Створюємо нові ознаки 'start_hour' і 'morning' для навчальної і тестової вибірок\n","train_df['start_hour'] = train_df['time1'].apply(lambda x: x.hour)\n","train_df['morning'] = train_df['start_hour'].apply(lambda x: 1 if x <= 11 else 0)\n","\n","test_df['start_hour'] = test_df['time1'].apply(lambda x: x.hour)\n","test_df['morning'] = test_df['start_hour'].apply(lambda x: 1 if x <= 11 else 0)\n","\n","# Нормалізуємо 'year_month' і 'start_hour' за допомогою StandardScaler\n","scaler = StandardScaler()\n","\n","# Масштабування ознак для тренувальної і тестової вибірок\n","train_features_for_scaling = train_df[['year_month', 'start_hour']]\n","test_features_for_scaling = test_df[['year_month', 'start_hour']]\n","\n","train_features_scaled = scaler.fit_transform(train_features_for_scaling)\n","test_features_scaled = scaler.transform(test_features_for_scaling)\n","\n","# Ознака 'morning' без масштабування (бінарна ознака)\n","train_morning = train_df[['morning']].values\n","test_morning = test_df[['morning']].values\n","\n","# 1. Сайти + 'start_month' і 'start_hour'\n","X_train_1 = hstack([full_sites_sparse[:idx_split, :], train_features_scaled[:, 0].reshape(-1, 1), train_features_scaled[:, 1].reshape(-1, 1)])\n","X_test_1 = hstack([full_sites_sparse[idx_split:, :], test_features_scaled[:, 0].reshape(-1, 1), test_features_scaled[:, 1].reshape(-1, 1)])\n","\n","# 2. Сайти + 'start_month' і 'morning'\n","X_train_2 = hstack([full_sites_sparse[:idx_split, :], train_features_scaled[:, 0].reshape(-1, 1), train_morning])\n","X_test_2 = hstack([full_sites_sparse[idx_split:, :], test_features_scaled[:, 0].reshape(-1, 1), test_morning])\n","\n","# 3. Сайти + 'start_month', 'start_hour' і 'morning'\n","X_train_3 = hstack([full_sites_sparse[:idx_split, :], train_features_scaled[:, 0].reshape(-1, 1), train_features_scaled[:, 1].reshape(-1, 1), train_morning])\n","X_test_3 = hstack([full_sites_sparse[idx_split:, :], test_features_scaled[:, 0].reshape(-1, 1), test_features_scaled[:, 1].reshape(-1, 1), test_morning])\n","\n","# Використовуємо функцію get_auc_lr_valid для обчислення AUC-ROC на відкладеній вибірці для кожного варіанту\n","\n","# Сайти + 'start_month' і 'start_hour'\n","auc_score_1 = get_auc_lr_valid(X_train_1, y_train.values, C=1.0, ratio=0.9)\n","print(f'AUC-ROC на валідаційній вибірці для сайтів, start_month і start_hour: {auc_score_1:.4f}')\n","\n","# Сайти + 'start_month' і 'morning'\n","auc_score_2 = get_auc_lr_valid(X_train_2, y_train.values, C=1.0, ratio=0.9)\n","print(f'AUC-ROC на валідаційній вибірці для сайтів, start_month і morning: {auc_score_2:.4f}')\n","\n","# Сайти + 'start_month', 'start_hour' і 'morning'\n","auc_score_3 = get_auc_lr_valid(X_train_3, y_train.values, C=1.0, ratio=0.9)\n","print(f'AUC-ROC на валідаційній вибірці для сайтів, start_month, start_hour і morning: {auc_score_3:.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"BICIGCSsT7df"},"source":["### 4. Підбір коефіцієнта регуляризації\n","\n","Отже, ми ввели ознаки, які покращують якість нашої моделі у порівнянні з першим бейслайном. Чи можемо ми домогтися більшого значення метрики? Після того, як ми сформували навчальну та тестову вибірки, майже завжди має сенс підібрати оптимальні гіперпараметри - характеристики моделі, які не змінюються під час навчання. Наприклад, ви вивчали вирішальні дерева, глибина дерева це гіперпараметр, а ознака, за якому відбувається розгалуження і її значення - ні. У використовуваної нами логістичної регресії ваги кожної ознаки змінюються і під час навчання знаходяться їх оптимальні значення, а коефіцієнт регуляризації залишається постійним. Це той гіперпараметр, який ми зараз будемо оптимізувати.\n","\n","Порахуйте якість на відкладеній вибірці з коефіцієнтом регуляризації, який за замовчуванням `C = 1 ':"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"zSd56_TtT7df"},"outputs":[{"name":"stdout","output_type":"stream","text":["AUC-ROC на валідаційній вибірці з коефіцієнтом регуляризації C=1: 0.9591\n"]}],"source":["# Підрахуємо AUC-ROC на валідаційній вибірці з коефіцієнтом регуляризації C = 1\n","auc_score = get_auc_lr_valid(X_train_3, y_train.values, C=1.0, ratio=0.9)\n","\n","# Виведемо результат\n","print(f'AUC-ROC на валідаційній вибірці з коефіцієнтом регуляризації C=1: {auc_score:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"VgyR4THVT7dm"},"source":["Постараємося побити цей результат за рахунок оптимізації коефіцієнта регуляризації. Візьмемо набір можливих значень C і для кожного з них порахуємо значення метрики на відкладеної вибірці.\n","\n","Знайдіть `C` з` np.logspace (-3, 1, 10) `, при якому ROC AUC на відкладеної вибірці максимальний."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"NUex1oHvT7dm"},"outputs":[{"name":"stdout","output_type":"stream","text":["C=0.0010, AUC-ROC=0.8239\n","C=0.0028, AUC-ROC=0.8934\n","C=0.0077, AUC-ROC=0.9398\n","C=0.0215, AUC-ROC=0.9564\n","C=0.0599, AUC-ROC=0.9605\n","C=0.1668, AUC-ROC=0.9611\n","C=0.4642, AUC-ROC=0.9603\n","C=1.2915, AUC-ROC=0.9586\n","C=3.5938, AUC-ROC=0.9557\n","C=10.0000, AUC-ROC=0.9513\n","Найкраще значення C: 0.1668, AUC-ROC: 0.9611\n"]}],"source":["# Створимо список можливих значень C\n","C_values = np.logspace(-3, 1, 10)\n","\n","# Змінна для зберігання найкращого значення C і відповідного AUC-ROC\n","best_auc = 0\n","best_C = None\n","\n","# Перебираємо всі значення C\n","for C in C_values:\n","    # Обчислюємо AUC-ROC на валідаційній вибірці для поточного значення C\n","    auc_score = get_auc_lr_valid(X_train_3, y_train.values, C=C, ratio=0.9)\n","    \n","    # Виведемо результат для кожного значення C\n","    print(f'C={C:.4f}, AUC-ROC={auc_score:.4f}')\n","    \n","    # Якщо поточне значення AUC-ROC більше за найкраще, зберігаємо його\n","    if auc_score > best_auc:\n","        best_auc = auc_score\n","        best_C = C\n","\n","# Виведемо найкращий результат\n","print(f'Найкраще значення C: {best_C:.4f}, AUC-ROC: {best_auc:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"FA64y9S-T7ds"},"source":["Нарешті, навчіть модель зі знайденим оптимальним значенням коефіцієнта регуляризації і з побудованими ознаками `start_hour`,` start_month` і `morning`. "]},{"cell_type":"code","execution_count":35,"metadata":{"id":"gHKSaYGpT7dt"},"outputs":[{"name":"stdout","output_type":"stream","text":["Модель навчено та результати збережено у файлі 'submission_final.csv'.\n"]}],"source":["# Навчимо модель на всій навчальній вибірці зі знайденим оптимальним значенням C\n","best_C = 0.1668\n","\n","# Використовуємо об'єднану матрицю ознак (сайти + start_month + start_hour + morning)\n","logreg_final = LogisticRegression(C=best_C, random_state=17, solver='liblinear')\n","\n","# Навчання моделі на повній вибірці\n","logreg_final.fit(X_train_3, y_train.values)\n","\n","# Прогноз на тестовій вибірці\n","y_test_pred = logreg_final.predict_proba(X_test_3)[:, 1]\n","\n","# Записуємо результат у файл\n","write_to_submission_file(y_test_pred, 'submission_final.csv')\n","\n","print(\"Модель навчено та результати збережено у файлі 'submission_final.csv'.\")"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
